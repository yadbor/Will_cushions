---
title: "will_data"
format: 
  html:
    self-contained: true
params:
  hide_answer: false
---

## Exploratory analysis of Will's data

This report contains R code and output intermingled using Quarto, 
based on the Literate Programming paradigm of Knuth.

Will's spreadsheets needed a lot of massage to make into sensible data.
The internal layout contains redundant formulae and a **lot** of apparantly
hand--entered numbers.

This should be properly structured to use the results generated by `BlueHill` 
directly whenever possible, to avoid typos and to make it more obvious to other
people (including future Will) what was done.

## Preparation

Load the necessary libraries.

```{r}
#| echo: true
#| message: false
# Load required libraries.
library(dplyr)
library(TOSTER)
library(ggplot2)

```

Will's data do not include density, but given the known relationship between
density & these results probably should roughly check for outliers by weighing
each cushion.

## Load the calculated results

Now load the reconstructed test results, 
rearrange them for easier automated processing and
calculate some summary statistics.

```{r}
# Read the testing results
data_file <- here::here("data", "reconstructed.xlsx")

# Display sheet names
sheet_names <- readxl::excel_sheets(data_file)
print(sheet_names)
```

From the available sheets, start with `hysteresis` and `lcdod`, 
the same as Liv's data.

```{r}
# Read the two sheets constructed from Will's data
sheet_names <- c("hysteresis", "lcdod")
# list the columns to use from each sheet
col_names <- list(
  hysteresis = "cushion, rep, H_250, H_500",
  lcdod =  "cushion, rep, L_180, L_225"
)

# Convert to long form for easier analysis,
# then combine both data sets by row and
# group by foam type, variable and the load level for each result
will_data <- sheet_names %>%                  # Take the named sheets
  purrr::set_names() %>%                     # make them a named list
  purrr::map(                                # apply a function to each element
    function(x) {
      these_cols <- col_names[[x]] %>% 
        stringr::str_split_1(",\\s*")        # Wanted cols for this sheet
      readxl::read_excel(data_file, x) %>%   # read the named sheet
        select(!!these_cols) %>%             # only the named columns
      tidyr::pivot_longer(cols = where(is.numeric), # use the results columns
                   names_to = "level",       # column names to 'level'
                   values_to = "value"       # each value to 'value'
                  )
    }
  ) %>%
  bind_rows(.id = "var") %>%      # combine by rows, original names in 'var'
  group_by(cushion, var, level) # make groups for each measurement

# Now have a table with columns named
# var = lcdod or hysteresis
# cushion = cushion ID number
# rep = A, B, C - the repeat of each test
# level = load level for measurement
# value = measurement

# Define a function to calculate the span of the given percentile
# percentile defaults to 95% (0.95)
CI = function(sd, percentile = 0.95) {
  interval = (percentile + 1)/2
  qnorm(p = interval, mean = 0, sd = sd)
}

# Show the Summary stats for each variable,including the 95% CI
will_summary <- will_data %>%
  summarise(avg = mean(value), sd = sd(value), n = n()) %>%
  mutate(delta = CI(sd, 0.95), lo_95 = avg - delta, hi_95 = avg + delta) %>%
  select(-delta) %>%
  arrange(var, level)

print(will_summary)
```

```{r}
# Make some simple box plots to show the spread of the data
plots <- list()
for (var_name in unique(will_data$var)) {
  plots[[var_name]] <- will_data %>%
    filter(var == var_name) %>%
    ggplot() +
    aes(y = value, x = cushion, colour = cushion) +
    geom_boxplot() +
    geom_jitter(colour = "black", width = 0.25) +
    labs(title = var_name, y = var_name) +
    facet_grid(level ~ .)
}
print(plots)
```

## TOST or equivalence testing

Run a **T**wo **O**ne **S**ided **T**est on each comparison group 
(i.e. compare foams for each measured variable and level)


```{r}
# Want to compare foams for each variable and level.
# Regroup the data with the required groups them map a function to each group
result_list <- will_data %>% 
  ungroup() %>% # remove the old groups first
  group_by(var, level) %>% # then regroup
  group_map( 
    function(data = .x, group = foam, values = value) {
      # t_TOST compares two vectors, create those from 
      # the groups defined by the `group` column
      #df <- select(data, !!group, !!values)
      bits <- split(data, ~ {{group}}) # this sprays Warnings
      # then extract the values to compare from the `values` column
      x <- pull(bits[[1]], {{values}});
      y <- pull(bits[[2]], {{values}});
      # Set the size of the equivalence bounds at 10% of the combined mean 
      mean_all = mean(c(x, y)) / 10;
      # Then do a TOST using that bound size (half above and half below).
      TOSTER::t_TOST(x, y, eqb = mean_all / 2) 
    }
  ) 
```


```{r}
# Lots of fuss to get the group names back to name the result list
keys <- will_data %>% 
    ungroup() %>% # remove the old groups first
    group_by(var, level) %>% group_keys()
result_names <- paste(keys$var, keys$level)

names(result_list) <- result_names
```


```{r}
# Turn output back on
#| output: asis
print(result_list)
```


`r if (params$hide_answer) "::: {.content-hidden}"`

## Possible Issues

Whys does `lcdod` appear to have a trend over time?

```{r}

will_data %>% 
  filter(var == "lcdod") %>%
  ggplot() +
    aes(y = value, x = as.factor(cushion)) +
    geom_jitter(colour = "black", width = 0.25) +
    geom_smooth() +
    labs(title = var_name, y = var_name) +
    facet_grid(level ~ .)

```

`r if (params$hide_answer) ":::"`
